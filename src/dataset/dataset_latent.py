"""
Dataset for loading latent representations from NPZ files.

This dataset loads pre-computed latent representations generated by surface_to_latent.py.
Each NPZ file contains:
- latent_params: (B, latent_dim) - latent representations of B surfaces
- rotations: (B, 6) - first 6 elements of rotation matrices
- scales: (B, 1) - scale values
- shifts: (B, 3) - translation vectors
- classes: (B, 1) - surface type indices (0-4)
"""

import torch
from torch.utils.data import Dataset
import numpy as np
from pathlib import Path
from typing import Tuple
import warnings


class LatentDataset(Dataset):
    """
    Dataset for loading latent surface representations from NPZ files.
    
    Each sample is a complete NPZ file containing multiple surfaces' latent representations.
    The data is padded to max_num_surfaces to ensure consistent batch sizes.
    """
    
    def __init__(self, npz_dir: str, max_num_surfaces: int = 500, latent_dim: int = 128):
        """
        Args:
            npz_dir: Path to directory containing NPZ files
            max_num_surfaces: Maximum number of surfaces per file for padding
            latent_dim: Dimension of the latent space (default: 128)
        """
        super().__init__()
        self.npz_dir = Path(npz_dir)
        self.max_num_surfaces = max_num_surfaces
        self.latent_dim = latent_dim
        
        # Discover all NPZ files in directory and subdirectories
        self.npz_files = sorted([
            str(p) for p in self.npz_dir.rglob("*.npz")
        ])
        
        if not self.npz_files:
            raise ValueError(f"No NPZ files found in {npz_dir}")
        
        print(f"Found {len(self.npz_files)} NPZ files in {npz_dir}")
        
        self.replica = 1
    
    def __len__(self):
        """Return number of NPZ files in the dataset."""
        return len(self.npz_files)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Load and return data from a single NPZ file.
        
        Args:
            idx: Index of the NPZ file
            
        Returns:
            Tuple containing:
            - latent_params: (max_num_surfaces, latent_dim) - padded latent representations
            - rotations: (max_num_surfaces, 6) - padded rotation data (first 6 elements of rotation matrices)
            - scales: (max_num_surfaces, 1) - padded scale values
            - shifts: (max_num_surfaces, 3) - padded translation vectors
            - classes: (max_num_surfaces,) - padded surface type indices
            - mask: (max_num_surfaces,) - binary mask indicating valid surfaces (1) vs padding (0)
        """
        npz_path = self.npz_files[idx]
        
        # Initialize padded arrays
        all_latent_params = np.zeros((self.max_num_surfaces, self.latent_dim), dtype=np.float32)
        all_rotations = np.zeros((self.max_num_surfaces, 6), dtype=np.float32)
        all_scales = np.zeros((self.max_num_surfaces, 1), dtype=np.float32)
        all_shifts = np.zeros((self.max_num_surfaces, 3), dtype=np.float32)
        all_classes = np.zeros(self.max_num_surfaces, dtype=np.int64)
        mask = np.zeros(self.max_num_surfaces, dtype=np.float32)
        
        try:
            # Load NPZ file
            data = np.load(npz_path)
            
            # Extract data
            latent_params = data['latent_params']  # (B, latent_dim)
            rotations = data['rotations']          # (B, 6)
            scales = data['scales']                # (B, 1)
            shifts = data['shifts']                # (B, 3)
            classes = data['classes']              # (B, 1)
            
            # Get number of valid surfaces
            num_surfaces = min(len(latent_params), self.max_num_surfaces)
            
            if num_surfaces == 0:
                warnings.warn(f"NPZ file {npz_path} contains no surfaces")
                return (
                    torch.from_numpy(all_latent_params).float(),
                    torch.from_numpy(all_rotations).float(),
                    torch.from_numpy(all_scales).float(),
                    torch.from_numpy(all_shifts).float(),
                    torch.from_numpy(all_classes).long(),
                    torch.from_numpy(mask).float()
                )
            
            # Fill in the data (up to max_num_surfaces)
            all_latent_params[:num_surfaces] = latent_params[:num_surfaces]
            all_rotations[:num_surfaces] = rotations[:num_surfaces]
            all_scales[:num_surfaces] = scales[:num_surfaces]
            all_shifts[:num_surfaces] = shifts[:num_surfaces]
            all_classes[:num_surfaces] = classes[:num_surfaces].squeeze(-1)  # Remove last dimension if present
            mask[:num_surfaces] = 1.0
            
            if num_surfaces < len(latent_params):
                warnings.warn(f"NPZ file {npz_path} contains {len(latent_params)} surfaces, "
                            f"but only using first {num_surfaces} (max_num_surfaces={self.max_num_surfaces})")
        
        except Exception as e:
            warnings.warn(f"Error loading NPZ file {npz_path}: {e}")
            # Return zero-filled arrays with no valid surfaces
        
        # Convert to tensors
        latent_params_tensor = torch.from_numpy(all_latent_params).float()
        rotations_tensor = torch.from_numpy(all_rotations).float()
        scales_tensor = torch.from_numpy(all_scales).float()
        shifts_tensor = torch.from_numpy(all_shifts).float()
        classes_tensor = torch.from_numpy(all_classes).long()
        mask_tensor = torch.from_numpy(mask).float()
        
        return (
            latent_params_tensor,
            rotations_tensor,
            scales_tensor,
            shifts_tensor,
            classes_tensor,
            mask_tensor
        )
    
    def get_file_info(self, idx: int) -> dict:
        """
        Get file information for inspection.
        
        Args:
            idx: Index of the NPZ file
            
        Returns:
            Dictionary containing file path and data shapes
        """
        npz_path = self.npz_files[idx]
        
        try:
            data = np.load(npz_path)
            info = {
                'npz_path': npz_path,
                'num_surfaces': len(data['latent_params']),
                'latent_params_shape': data['latent_params'].shape,
                'rotations_shape': data['rotations'].shape,
                'scales_shape': data['scales'].shape,
                'shifts_shape': data['shifts'].shape,
                'classes_shape': data['classes'].shape,
            }
            return info
        except Exception as e:
            return {
                'npz_path': npz_path,
                'error': str(e)
            }


class LatentDatasetFlat(Dataset):
    """
    Flattened version of LatentDataset where each surface is treated as a separate sample.
    
    This is useful for training models that process individual surfaces rather than
    sequences of surfaces from the same file.
    """
    
    def __init__(self, npz_dir: str, latent_dim: int = 128):
        """
        Args:
            npz_dir: Path to directory containing NPZ files
            latent_dim: Dimension of the latent space (default: 128)
        """
        super().__init__()
        self.npz_dir = Path(npz_dir)
        self.latent_dim = latent_dim
        
        # Discover all NPZ files in directory and subdirectories
        npz_files = sorted([
            str(p) for p in self.npz_dir.rglob("*.npz")
        ])
        
        if not npz_files:
            raise ValueError(f"No NPZ files found in {npz_dir}")
        
        # Build index mapping: (file_idx, surface_idx) for each surface
        self.surface_indices = []
        for file_idx, npz_path in enumerate(npz_files):
            try:
                data = np.load(npz_path)
                num_surfaces = len(data['latent_params'])
                for surf_idx in range(num_surfaces):
                    self.surface_indices.append((file_idx, surf_idx, npz_path))
            except Exception as e:
                warnings.warn(f"Error scanning NPZ file {npz_path}: {e}")
                continue
        
        print(f"Found {len(self.surface_indices)} surfaces across {len(npz_files)} NPZ files")
        
        self.replica = 1
    
    def __len__(self):
        """Return total number of surfaces across all NPZ files."""
        return len(self.surface_indices)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Load and return data for a single surface.
        
        Args:
            idx: Index of the surface (flattened across all files)
            
        Returns:
            Tuple containing:
            - latent_params: (latent_dim,) - latent representation
            - rotation: (6,) - rotation data (first 6 elements of rotation matrix)
            - scale: (1,) - scale value
            - shift: (3,) - translation vector
            - class_label: scalar - surface type index
        """
        file_idx, surf_idx, npz_path = self.surface_indices[idx]
        
        try:
            # Load NPZ file
            data = np.load(npz_path)
            
            # Extract surface data
            latent_params = data['latent_params'][surf_idx]  # (latent_dim,)
            rotation = data['rotations'][surf_idx]           # (6,)
            scale = data['scales'][surf_idx]                 # (1,)
            shift = data['shifts'][surf_idx]                 # (3,)
            class_label = data['classes'][surf_idx]          # (1,) or scalar
            
            # Ensure class_label is scalar
            if hasattr(class_label, '__len__'):
                class_label = class_label[0]
            
            # Convert to tensors
            return (
                torch.from_numpy(latent_params).float(),
                torch.from_numpy(rotation).float(),
                torch.from_numpy(scale).float(),
                torch.from_numpy(shift).float(),
                torch.tensor(class_label, dtype=torch.long)
            )
        
        except Exception as e:
            warnings.warn(f"Error loading surface {surf_idx} from {npz_path}: {e}")
            # Return zero-filled data
            return (
                torch.zeros(self.latent_dim, dtype=torch.float32),
                torch.zeros(6, dtype=torch.float32),
                torch.zeros(1, dtype=torch.float32),
                torch.zeros(3, dtype=torch.float32),
                torch.tensor(0, dtype=torch.long)
            )


if __name__ == '__main__':
    import sys
    from tqdm import tqdm
    
    if len(sys.argv) < 2:
        print("Usage: python dataset_latent.py <npz_directory>")
        sys.exit(1)
    
    npz_dir = sys.argv[1]
    
    # Test LatentDataset
    print("="*80)
    print("Testing LatentDataset (grouped by file):")
    print("="*80)
    dataset = LatentDataset(npz_dir)
    print(f"Dataset length: {len(dataset)}")
    
    # Test first sample
    if len(dataset) > 0:
        print("\nTesting first sample:")
        latent_params, rotations, scales, shifts, classes, mask = dataset[0]
        num_valid = mask.sum().item()
        print(f"  File: {dataset.npz_files[0]}")
        print(f"  Number of valid surfaces: {num_valid}")
        print(f"  Latent params shape: {latent_params.shape}")
        print(f"  Rotations shape: {rotations.shape}")
        print(f"  Scales shape: {scales.shape}")
        print(f"  Shifts shape: {shifts.shape}")
        print(f"  Classes shape: {classes.shape}")
        print(f"  Mask shape: {mask.shape}")
        
        # Show some statistics
        if num_valid > 0:
            print(f"\n  Valid surface classes: {classes[mask.bool()].tolist()}")
            print(f"  Valid surface scales: {scales[mask.bool()].squeeze().tolist()}")
    
    # Test LatentDatasetFlat
    print("\n" + "="*80)
    print("Testing LatentDatasetFlat (individual surfaces):")
    print("="*80)
    flat_dataset = LatentDatasetFlat(npz_dir)
    print(f"Flat dataset length: {len(flat_dataset)}")
    
    if len(flat_dataset) > 0:
        print("\nTesting first surface:")
        latent_params, rotation, scale, shift, class_label = flat_dataset[0]
        print(f"  Latent params shape: {latent_params.shape}")
        print(f"  Rotation shape: {rotation.shape}")
        print(f"  Scale shape: {scale.shape}")
        print(f"  Shift shape: {shift.shape}")
        print(f"  Class label: {class_label.item()}")
    
    # Iterate through dataset to check for errors
    print("\n" + "="*80)
    print("Scanning all files for errors:")
    print("="*80)
    error_count = 0
    for i in tqdm(range(len(dataset)), desc="Checking files"):
        try:
            _ = dataset[i]
        except Exception as e:
            print(f"\nError at index {i}: {e}")
            error_count += 1
    
    print(f"\nTotal errors: {error_count}/{len(dataset)}")
    print("="*80)

