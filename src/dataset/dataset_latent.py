"""
Dataset for loading latent representations from NPZ files.

This dataset loads pre-computed latent representations generated by surface_to_latent.py.
Each NPZ file contains:
- latent_params: (B, latent_dim) - latent representations of B surfaces
- rotations: (B, 6) - first 6 elements of rotation matrices
- scales: (B, 1) - scale values
- shifts: (B, 3) - translation vectors
- classes: (B, 1) - surface type indices (0-4)
"""

import torch
from torch.utils.data import Dataset
import numpy as np
from pathlib import Path
from typing import Tuple
import warnings


class LatentDataset(Dataset):
    """
    Dataset for loading latent surface representations from NPZ files.
    
    Each sample is a complete NPZ file containing multiple surfaces' latent representations.
    The data is padded to max_num_surfaces to ensure consistent batch sizes.
    """
    
    def __init__(self, latent_dir: str, pc_dir: str, max_num_surfaces: int = 500, latent_dim: int = 128, num_data: int = -1):
        """
        Args:
            npz_dir: Path to directory containing NPZ files
            max_num_surfaces: Maximum number of surfaces per file for padding
            latent_dim: Dimension of the latent space (default: 128)
        """
        super().__init__()
        print('latent_dir: ', latent_dir)
        self.latent_dir = Path(latent_dir)
        self.pc_dir = pc_dir
        self.max_num_surfaces = max_num_surfaces
        self.latent_dim = latent_dim
        
        # Discover all NPZ files in directory and subdirectories
        self.latent_files = sorted([
            str(p) for p in self.latent_dir.rglob("*.npz")
        ])
        if num_data > 0:
            self.latent_files = self.latent_files[:num_data]
        self.latent_dir = str(self.latent_dir)
        if not self.latent_files:
            raise ValueError(f"No NPZ files found in {latent_dir}")
        
        print(f"Found {len(self.latent_files)} NPZ files in {latent_dir}")
        
        self.replica = 1
    
    def __len__(self):
        """Return number of NPZ files in the dataset."""
        return len(self.latent_files)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Load and return data from a single NPZ file.
        
        Args:
            idx: Index of the NPZ file
            
        Returns:
            Tuple containing:
            - latent_params: (max_num_surfaces, latent_dim) - padded latent representations
            - rotations: (max_num_surfaces, 6) - padded rotation data (first 6 elements of rotation matrices)
            - scales: (max_num_surfaces, 1) - padded scale values
            - shifts: (max_num_surfaces, 3) - padded translation vectors
            - classes: (max_num_surfaces,) - padded surface type indices
            - bbox_mins: (max_num_surfaces, 3) - padded bounding box minimums
            - bbox_maxs: (max_num_surfaces, 3) - padded bounding box maximums
            - mask: (max_num_surfaces,) - binary mask indicating valid surfaces (1) vs padding (0)
        """
        latent_path = self.latent_files[idx]
        pc_path = self.latent_files[idx].replace(self.latent_dir, self.pc_dir).replace('.npz', '_latent.npy')

        # Initialize padded arrays
        all_latent_params = np.zeros((self.max_num_surfaces, self.latent_dim), dtype=np.float32)
        all_rotations = np.zeros((self.max_num_surfaces, 6), dtype=np.float32)
        all_scales = np.zeros((self.max_num_surfaces, 1), dtype=np.float32)
        all_shifts = np.zeros((self.max_num_surfaces, 3), dtype=np.float32)
        all_classes = np.zeros(self.max_num_surfaces, dtype=np.int64)
        all_bbox_mins = np.zeros((self.max_num_surfaces, 3), dtype=np.float32)
        all_bbox_maxs = np.zeros((self.max_num_surfaces, 3), dtype=np.float32)
        mask = np.zeros(self.max_num_surfaces, dtype=np.float32)
        
        try:
            # Load NPZ file
            data = np.load(latent_path)
            
            # Extract data
            latent_params = data['latent_params']  # (B, latent_dim)
            rotations = data['rotations']          # (B, 6)
            scales = data['scales']                # (B, 1)
            shifts = data['shifts']                # (B, 3)
            classes = data['classes']              # (B, 1)
            
            # Extract bounding box data if available (for backward compatibility)
            bbox_mins = data.get('bbox_mins', np.zeros((len(latent_params), 3)))  # (B, 3)
            bbox_maxs = data.get('bbox_maxs', np.zeros((len(latent_params), 3)))  # (B, 3)
            
            # Get number of valid surfaces
            num_surfaces = min(len(latent_params), self.max_num_surfaces)
            
            if num_surfaces == 0:
                warnings.warn(f"NPZ file {latent_path} contains no surfaces")
                return (
                    torch.from_numpy(all_latent_params).float(),
                    torch.from_numpy(all_rotations).float(),
                    torch.from_numpy(all_scales).float(),
                    torch.from_numpy(all_shifts).float(),
                    torch.from_numpy(all_classes).long(),
                    torch.from_numpy(all_bbox_mins).float(),
                    torch.from_numpy(all_bbox_maxs).float(),
                    torch.from_numpy(mask).float()
                )
            
            # Fill in the data (up to max_num_surfaces)
            all_latent_params[:num_surfaces] = latent_params[:num_surfaces]
            all_rotations[:num_surfaces] = rotations[:num_surfaces]
            all_scales[:num_surfaces] = scales[:num_surfaces]
            all_shifts[:num_surfaces] = shifts[:num_surfaces]
            all_classes[:num_surfaces] = classes[:num_surfaces].squeeze(-1)  # Remove last dimension if present
            all_bbox_mins[:num_surfaces] = bbox_mins[:num_surfaces]
            all_bbox_maxs[:num_surfaces] = bbox_maxs[:num_surfaces]
            mask[:num_surfaces] = 1.0
            
            if num_surfaces < len(latent_params):
                warnings.warn(f"NPZ file {latent_path} contains {len(latent_params)} surfaces, "
                            f"but only using first {num_surfaces} (max_num_surfaces={self.max_num_surfaces})")

            pc = np.load(pc_path)

        
        except Exception as e:
            warnings.warn(f"Error loading NPZ file {latent_path}: {e}")
            # Return zero-filled arrays with no valid surfaces
        
        # Convert to tensors
        latent_params_tensor = torch.from_numpy(all_latent_params).float()
        rotations_tensor = torch.from_numpy(all_rotations).float()
        scales_tensor = torch.from_numpy(all_scales).float()
        shifts_tensor = torch.from_numpy(all_shifts).float()
        classes_tensor = torch.from_numpy(all_classes).long()
        bbox_mins_tensor = torch.from_numpy(all_bbox_mins).float()
        bbox_maxs_tensor = torch.from_numpy(all_bbox_maxs).float()
        mask_tensor = torch.from_numpy(mask).float()
        pc_tensor = torch.from_numpy(pc).float()
        return (
            latent_params_tensor,
            rotations_tensor,
            scales_tensor,
            shifts_tensor,
            classes_tensor,
            bbox_mins_tensor,
            bbox_maxs_tensor,
            mask_tensor,
            pc_tensor
        )
    
    def get_file_info(self, idx: int) -> dict:
        """
        Get file information for inspection.
        
        Args:
            idx: Index of the NPZ file
            
        Returns:
            Dictionary containing file path and data shapes
        """
        latent_path = self.latent_files[idx]
        
        try:
            data = np.load(latent_path)
            info = {
                'latent_path': latent_path,
                'num_surfaces': len(data['latent_params']),
                'latent_params_shape': data['latent_params'].shape,
                'rotations_shape': data['rotations'].shape,
                'scales_shape': data['scales'].shape,
                'shifts_shape': data['shifts'].shape,
                'classes_shape': data['classes'].shape,
                'has_bbox': 'bbox_mins' in data and 'bbox_maxs' in data,
            }
            if info['has_bbox']:
                info['bbox_mins_shape'] = data['bbox_mins'].shape
                info['bbox_maxs_shape'] = data['bbox_maxs'].shape
            return info
        except Exception as e:
            return {
                'latent_path': latent_path,
                'error': str(e)
            }




if __name__ == '__main__':
    import sys
    from tqdm import tqdm
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--npz_dir', type=str, required=True)
    parser.add_argument('--pc_dir', type=str, required=True)
    parser.add_argument('--max_num_surfaces', type=int, default=500)
    parser.add_argument('--latent_dim', type=int, default=128)
    args = parser.parse_args()
    
    # Test LatentDataset
    print("="*80)
    print("Testing LatentDataset (grouped by file):")
    print("="*80)
    dataset = LatentDataset(args.npz_dir, args.pc_dir, args.max_num_surfaces, args.latent_dim)
    print(f"Dataset length: {len(dataset)}")
    
    # Test first sample
    if len(dataset) > 0:
        print("\nTesting first sample:")
        for i in tqdm(range(len(dataset))):
            latent_params, rotations, scales, shifts, classes, bbox_mins, bbox_maxs, mask, pc = dataset[i]


        
    # Test LatentDatasetFlat
