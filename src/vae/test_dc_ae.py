"""
DC-AE ç‹¬ç«‹æ¨¡å—æµ‹è¯•
æµ‹è¯•ç²¾ç®€ç‰ˆ DC-AE çš„åŠŸèƒ½
"""

import torch
import torch.nn as nn
from dc_ae import DCAE, DCAEConfig, EncoderConfig, DecoderConfig, create_minimal_dcae


def test_minimal_config():
    """æµ‹è¯•æœ€å°åŒ–é…ç½®ï¼š4x4x3 -> 2x2x3"""
    print("=" * 70)
    print("æµ‹è¯• 1: æœ€å°åŒ–é…ç½® (4x4x3 -> 2x2x3)")
    print("=" * 70)
    
    # æ–¹æ³•1: æ‰‹åŠ¨é…ç½®
    config = DCAEConfig(
        in_channels=3,
        latent_channels=3,
        encoder=EncoderConfig(
            in_channels=3,
            latent_channels=3,
            width_list=(64, 128),
            depth_list=(1, 1),
            block_type="ResBlock",
            norm="bn2d",
            act="relu",
            downsample_block_type="ConvPixelUnshuffle",
            downsample_match_channel=True,
            downsample_shortcut="averaging",
            out_norm="bn2d",
            out_act="relu",
            out_shortcut=None,  # ç§»é™¤shortcuté¿å…é€šé“æ•°ä¸åŒ¹é…é—®é¢˜
        ),
        decoder=DecoderConfig(
            in_channels=3,
            latent_channels=3,
            in_shortcut=None,        # ç§»é™¤in_shortcuté¿å…é€šé“æ•°ä¸åŒ¹é…é—®é¢˜
            width_list=(64, 128),
            depth_list=(1, 1),
            block_type="ResBlock",
            norm="bn2d",
            act="relu",
            upsample_block_type="ConvPixelShuffle",
            upsample_match_channel=True,
            upsample_shortcut=None,  # ç§»é™¤shortcuté¿å…é€šé“æ•°ä¸åŒ¹é…é—®é¢˜
            out_norm="bn2d",
            out_act="relu",
        ),
    )
    
    model = DCAE(config)
    model.eval()
    
    # æµ‹è¯•æ•°æ®
    batch_size = 4
    x = torch.randn(batch_size, 3, 4, 4)
    
    print(f"\nè¾“å…¥å½¢çŠ¶: {tuple(x.shape)}")
    
    # ç¼–ç 
    with torch.no_grad():
        latent = model.encode(x)
    print(f"Latentå½¢çŠ¶: {tuple(latent.shape)}")
    assert latent.shape == (batch_size, 3, 2, 2), f"Latent shapeé”™è¯¯: {latent.shape}"
    
    # è§£ç 
    with torch.no_grad():
        recon = model.decode(latent)
    print(f"é‡å»ºå½¢çŠ¶: {tuple(recon.shape)}")
    assert recon.shape == x.shape, f"é‡å»ºshapeé”™è¯¯: {recon.shape}"
    
    # è®¡ç®—æŸå¤±
    mse = nn.functional.mse_loss(recon, x)
    print(f"\nMSE Loss (æœªè®­ç»ƒ): {mse.item():.4f}")
    
    print(f"âœ“ æµ‹è¯•é€šè¿‡!")
    print(f"  å‹ç¼©æ¯”: {model.spatial_compression_ratio}x")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    return model


def test_helper_function():
    """æµ‹è¯•ä¾¿æ·åˆ›å»ºå‡½æ•°"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: ä½¿ç”¨ä¾¿æ·å‡½æ•° create_minimal_dcae()")
    print("=" * 70)
    
    # ä½¿ç”¨ä¾¿æ·å‡½æ•°
    model = create_minimal_dcae(input_size=4, in_channels=3, latent_channels=3, width_base=64)
    model.eval()
    
    x = torch.randn(2, 3, 4, 4)
    print(f"\nè¾“å…¥å½¢çŠ¶: {tuple(x.shape)}")
    
    with torch.no_grad():
        latent = model.encode(x)
        recon = model.decode(latent)
    
    print(f"Latentå½¢çŠ¶: {tuple(latent.shape)}")
    print(f"é‡å»ºå½¢çŠ¶: {tuple(recon.shape)}")
    
    print(f"âœ“ æµ‹è¯•é€šè¿‡!")
    
    return model


def test_different_sizes():
    """æµ‹è¯•ä¸åŒè¾“å…¥å°ºå¯¸"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: ä¸åŒè¾“å…¥å°ºå¯¸")
    print("=" * 70)
    
    model = create_minimal_dcae(input_size=8, in_channels=3, latent_channels=16, width_base=32)
    model.eval()
    
    test_cases = [
        (1, 3, 4, 4),
        (2, 3, 8, 8),
        (1, 3, 16, 16),
        (4, 3, 32, 32),
    ]
    
    for shape in test_cases:
        x = torch.randn(*shape)
        with torch.no_grad():
            latent = model.encode(x)
            recon = model.decode(latent)
        
        expected_latent_shape = (shape[0], 16, shape[2] // 2, shape[3] // 2)
        assert latent.shape == expected_latent_shape, f"Latent shapeä¸åŒ¹é…: {latent.shape} vs {expected_latent_shape}"
        assert recon.shape == shape, f"é‡å»ºshapeä¸åŒ¹é…: {recon.shape} vs {shape}"
        
        print(f"  {tuple(x.shape)} -> {tuple(latent.shape)} -> {tuple(recon.shape)} âœ“")
    
    print("âœ“ æ‰€æœ‰å°ºå¯¸æµ‹è¯•é€šè¿‡!")
    
    return model


def test_latent_manipulation():
    """æµ‹è¯• latent çš„ä¸åŒå±•å¹³æ–¹å¼"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: Latent å±•å¹³ä¸é‡å¡‘")
    print("=" * 70)
    
    model = create_minimal_dcae(input_size=4, in_channels=3, latent_channels=3)
    model.eval()
    
    x = torch.randn(2, 3, 4, 4)
    
    with torch.no_grad():
        latent = model.encode(x)  # (2, 3, 2, 2)
    
    print(f"\nåŸå§‹ Latent å½¢çŠ¶: {tuple(latent.shape)}")
    
    # ä¸åŒçš„å±•å¹³æ–¹å¼
    print("\nå±•å¹³æ–¹å¼:")
    
    # 1. å®Œå…¨å±•å¹³
    latent_flat = latent.view(2, -1)
    print(f"  1. å®Œå…¨å±•å¹³:       {tuple(latent_flat.shape)} -> {latent_flat.shape[1]} ä¸ªå€¼")
    
    # 2. ä¿ç•™é€šé“ç»´åº¦
    latent_spatial = latent.flatten(2)
    print(f"  2. å±•å¹³ç©ºé—´ç»´åº¦:   {tuple(latent_spatial.shape)}")
    
    # 3. è‡ªå®šä¹‰å½¢çŠ¶ 2x6
    latent_2x6 = latent.view(2, 2, 6)
    print(f"  3. é‡å¡‘ä¸º 2x6:     {tuple(latent_2x6.shape)}")
    
    # 4. è‡ªå®šä¹‰å½¢çŠ¶ 3x4
    latent_3x4 = latent.view(2, 3, 4)
    print(f"  4. é‡å¡‘ä¸º 3x4:     {tuple(latent_3x4.shape)}")
    
    # é‡å¡‘å›åŸå§‹å½¢çŠ¶å¹¶è§£ç 
    latent_reshaped = latent_flat.view(2, 3, 2, 2)
    with torch.no_grad():
        recon = model.decode(latent_reshaped)
    
    print(f"\né‡å¡‘åè§£ç : {tuple(recon.shape)}")
    print("âœ“ Latent æ“ä½œæµ‹è¯•é€šè¿‡!")
    
    return model


def test_forward_pass():
    """æµ‹è¯•å®Œæ•´çš„å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 5: å®Œæ•´å‰å‘ä¼ æ’­")
    print("=" * 70)
    
    model = create_minimal_dcae(input_size=4, in_channels=3, latent_channels=3)
    model.eval()
    
    x = torch.randn(2, 3, 4, 4)
    
    with torch.no_grad():
        recon, kl_loss, metrics = model(x, global_step=0)
    
    print(f"\nè¾“å…¥å½¢çŠ¶: {tuple(x.shape)}")
    print(f"é‡å»ºå½¢çŠ¶: {tuple(recon.shape)}")
    print(f"KL Loss: {kl_loss.item()}")
    print(f"Metrics: {metrics}")
    
    # è®¡ç®—é‡å»ºè¯¯å·®
    mse = nn.functional.mse_loss(recon, x)
    mae = nn.functional.l1_loss(recon, x)
    
    print(f"\né‡å»ºè¯¯å·® (æœªè®­ç»ƒ):")
    print(f"  MSE: {mse.item():.6f}")
    print(f"  MAE: {mae.item():.6f}")
    
    print("âœ“ å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡!")
    
    return model


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€" * 35)
    print(" " * 20 + "DC-AE ç‹¬ç«‹æ¨¡å—æµ‹è¯•å¥—ä»¶")
    print("ğŸš€" * 35 + "\n")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    model1 = test_minimal_config()
    model2 = test_helper_function()
    model3 = test_different_sizes()
    model4 = test_latent_manipulation()
    model5 = test_forward_pass()
    
    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 70)
    
    print("\nğŸ“‹ ä½¿ç”¨ç¤ºä¾‹:")
    print("""
from src.vae.dc_ae import create_minimal_dcae

# åˆ›å»ºæ¨¡å‹
model = create_minimal_dcae(
    input_size=4,
    in_channels=3,
    latent_channels=3,
    width_base=64
)

# ä½¿ç”¨æ¨¡å‹
x = torch.randn(batch_size, 3, 4, 4)
latent = model.encode(x)          # (B, 3, 2, 2)
recon = model.decode(latent)      # (B, 3, 4, 4)

# æˆ–è€…ç›´æ¥å‰å‘ä¼ æ’­
recon, kl_loss, metrics = model(x, global_step=0)
""")


if __name__ == "__main__":
    main()

