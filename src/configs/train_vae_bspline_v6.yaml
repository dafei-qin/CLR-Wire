# In this version, we add a loss for the xyz coordinates of the poles
resume_training: false
from_start: false

epochs: 100
batch_size: 16
lr: 0.0001
num_workers: 8
num_gpus: 8

grad_accum_every: 1
ema_update_every: 10
max_grad_norm: 1.0

val_every_epoch: 1
save_every_epoch: 5
log_every_step: 50

use_wandb_tracking: true
wandb_project_name: BSPLINE_VAE_V1
wandb_run_name: train_1127_bspline_6_latent128_lossxyz=100_64x32

data:
    train_file: ./assets/ram_all_bspline_surfaces.txt
    train_data_dir_override: ""
    train_num: -1
    val_file: ./assets/all_bspline_paths_test.txt
    val_data_dir_override: ""
    val_num: -1

trainer:
    use_logvar: false

model:
    name: vae_bspline_v6
    trainer_name: vae_bspline_v2
    mults_dim: 16
    embd_dim: 128
    max_num_u_knots: 64
    max_num_v_knots: 32
    max_num_u_poles: 64
    max_num_v_poles: 32
    checkpoint_folder: checkpoints/train_1117_bspline_6_latent128_lossxyz=100_64x32
    checkpoint_file_name: model-20.pt


loss:
    recon_weight: 1.0
    cls_weight: 1.0
    poles_xyz_weight: 100.0
    kl_weight: 0.001 # Add kl weights
    kl_annealing_steps: 20000  # Number of steps to anneal KL weight from 0 to kl_weight
    kl_free_bits: 32.0  # Free bits per sample (in nats)