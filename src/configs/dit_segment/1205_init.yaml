resume_training: false
from_start: false

epochs: 8000
batch_size: 512
lr: 0.0001
num_workers: 4
num_gpus: 8

grad_accum_every: 1
ema_update_every: 10
max_grad_norm: 1.0

val_every_epoch: 10
save_every_epoch: 50
log_every_step: 50

use_wandb_tracking: true
wandb_project_name: DIT_SIMPLE
wandb_run_name: 1204_dit_v2_simple_vae_pred_closed_large_rts

data_train:
    name: src.dataset.dataset_latent_segment.LatentDataset
    params:
        latent_dir: ../data/logan_jsons_latent_pred_closed/abc
        latent_dim: 128
        num_data: -1
        log_scale: true
        replica: 1
        max_num_surfaces: 32

data_val:
    name: src.dataset.dataset_latent_segment.LatentDataset
    params:
        latent_dir: ../data/logan_jsons_latent_pred_closed/abc_test
        pc_dir: ../data/logan_jsons_michel_latent/abc_test
        latent_dim: 128
        num_data: -1
        log_scale: true
        replica: 1
        max_num_surfaces: 32


trainer:
    use_logvar: false
    prediction_type: v_prediction
    num_inference_timesteps: 50


model:
    # name: dit_v2
    name: src.dit.simple_surface_decoder_segment.SimpleSurfaceDecoder
    trainer_name: dit_v1
    checkpoint_folder: checkpoints/1204_dit_v2_simple_vae_pred_closed_large_rts
    checkpoint_file_name: model-22.pt
    params:
        input_dim: 139
        cond_dim: 3
        output_dim: 139
        latent_dim: 384
        num_layers: 12
        num_heads: 6

vae:
    config_file: src/configs/train_vae_v1_canonical_logvar_l2norm_pred_closed.yaml

loss:
    weight_valid: 0.01
    weight_params: 1.0
    weight_rotations: 1.0
    weight_scales: 1.0
    weight_shifts: 1.0
    weight_original_sample: 1.0
