
resume_training: false
from_start: false

epochs: 100
batch_size: 16
lr: 0.0001
num_workers: 8
num_gpus: 8

grad_accum_every: 1
ema_update_every: 10
max_grad_norm: 1.0

val_every_epoch: 1
save_every_epoch: 5
log_every_step: 50

use_wandb_tracking: true
wandb_project_name: BSPLINE_VAE_V1
wandb_run_name: train_1202_bspline_7_knots_32x16

data:
    train_file: ./assets/all_bspline_paths.txt
    train_data_dir_override: ""
    train_num: 10000
    val_file: ./assets/all_bspline_paths_test.txt
    val_data_dir_override: ""
    val_num: 10000

trainer:
    use_logvar: true

model:
    name: vae_bspline_v7
    trainer_name: vae_bspline_v2
    mults_dim: 128
    embd_dim: 512
    max_num_u_knots: 32
    max_num_v_knots: 16
    max_num_u_poles: 64
    max_num_v_poles: 32
    checkpoint_folder: checkpoints/train_1202_bspline_7_knots_32x16
    checkpoint_file_name: model-20.pt


profiler:
    enable: true
    save_dir: checkpoints/train_1202_bspline_7_knots_32x16/profiler

loss:
    recon_weight: 1.0
    cls_weight: 1.0
    poles_xyz_weight: 100.0
    kl_weight: 0.001 # Add kl weights
    kl_annealing_steps: 20000  # Number of steps to anneal KL weight from 0 to kl_weight
    kl_free_bits: 32.0  # Free bits per sample (in nats)